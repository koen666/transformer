{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53940b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7f60f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 4, 0, 0, 0],\n",
      "        [5, 6, 5, 7, 0]])\n",
      "tensor([[2, 7, 3, 5, 0],\n",
      "        [3, 3, 7, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "batchsize=2\n",
    "max_num_src_words=8\n",
    "max_num_tgt_words=8\n",
    "model_dim=8\n",
    "\n",
    "max_src_seq_len=5\n",
    "max_tgt_seq_len=5\n",
    "max_position_len=5\n",
    "# src_len= torch.randint(2,5,(batchsize,))\n",
    "# tgt_len= torch.randint(2,5,(batchsize,))\n",
    "src_len=torch.Tensor([2,4]).to(torch.int32)\n",
    "tgt_len=torch.Tensor([4,3]).to(torch.int32)\n",
    "#单词索引序列构成源句子和目标锯子，并且做了padding\n",
    "src_seq=torch.cat([torch.unsqueeze(F.pad(torch.randint(1,max_num_src_words,(L,)),(0,max_src_seq_len-L)),0) for L in src_len])\n",
    "tgt_seq=torch.cat([torch.unsqueeze(F.pad(torch.randint(1,max_num_tgt_words,(L,)),(0,max_tgt_seq_len-L)),0) for L in tgt_len])\n",
    "print(src_seq)\n",
    "print(tgt_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a284d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2328, -0.0056,  0.2100, -1.1865, -0.9385,  0.4304, -0.9666,\n",
      "          -0.5284],\n",
      "         [ 1.2238,  1.2813,  0.2205, -0.6406, -0.4276, -0.4490, -0.5950,\n",
      "          -0.4858],\n",
      "         [ 0.1921, -1.1331, -0.2075, -0.0905, -0.3573, -0.9686, -0.9755,\n",
      "          -1.3524],\n",
      "         [ 0.1921, -1.1331, -0.2075, -0.0905, -0.3573, -0.9686, -0.9755,\n",
      "          -1.3524],\n",
      "         [ 0.1921, -1.1331, -0.2075, -0.0905, -0.3573, -0.9686, -0.9755,\n",
      "          -1.3524]],\n",
      "\n",
      "        [[ 0.2328, -0.0056,  0.2100, -1.1865, -0.9385,  0.4304, -0.9666,\n",
      "          -0.5284],\n",
      "         [-1.2628,  0.6543, -0.9529, -1.5322,  0.0348,  1.7021, -0.3497,\n",
      "          -0.5548],\n",
      "         [ 1.2238,  1.2813,  0.2205, -0.6406, -0.4276, -0.4490, -0.5950,\n",
      "          -0.4858],\n",
      "         [-0.1172,  0.9872,  0.5635,  0.5389, -0.1481,  0.3537,  1.5191,\n",
      "          -0.8734],\n",
      "         [ 0.1921, -1.1331, -0.2075, -0.0905, -0.3573, -0.9686, -0.9755,\n",
      "          -1.3524]]], grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[[-0.3116, -0.3202, -0.3221, -0.2326, -1.0052, -0.4584, -0.5882,\n",
      "          -0.2175],\n",
      "         [ 0.1938, -0.9331,  0.6965,  0.1912,  0.7956, -2.5678,  0.6250,\n",
      "          -0.4067],\n",
      "         [ 0.2388,  0.7672,  0.7626, -1.4829,  0.3725, -0.5907,  0.0814,\n",
      "           0.4036],\n",
      "         [-0.2166, -2.0822,  0.0999, -1.7581,  1.0674,  0.0640,  0.4905,\n",
      "           0.4996],\n",
      "         [ 1.2709,  1.6902,  0.1104, -0.2518,  0.5624, -0.6758, -1.4383,\n",
      "           0.4468]],\n",
      "\n",
      "        [[ 0.2388,  0.7672,  0.7626, -1.4829,  0.3725, -0.5907,  0.0814,\n",
      "           0.4036],\n",
      "         [ 0.8168,  0.8658,  0.3207,  1.0482, -0.9699,  0.0736,  1.2540,\n",
      "           0.6633],\n",
      "         [ 0.9057,  0.1953, -0.5689,  0.9805, -0.7549,  1.2908, -0.3421,\n",
      "           1.5309],\n",
      "         [ 1.2709,  1.6902,  0.1104, -0.2518,  0.5624, -0.6758, -1.4383,\n",
      "           0.4468],\n",
      "         [ 1.2709,  1.6902,  0.1104, -0.2518,  0.5624, -0.6758, -1.4383,\n",
      "           0.4468]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#构造embedding(索引table构造)\n",
    "src_embedding_table=nn.Embedding(max_num_src_words+1,model_dim)\n",
    "tgt_embedding_table=nn.Embedding(max_num_tgt_words+1,model_dim)\n",
    "src_embedding=src_embedding_table(src_seq)\n",
    "tgt_embedding=tgt_embedding_table(tgt_seq)\n",
    "print(src_embedding)\n",
    "print(tgt_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e03e911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
      "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
      "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
      "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
      "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
      "           9.9955e-01,  3.0000e-03,  1.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
      "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
      "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
      "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
      "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
      "           9.9955e-01,  3.0000e-03,  1.0000e+00]]])\n",
      "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
      "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
      "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
      "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
      "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
      "           9.9955e-01,  3.0000e-03,  1.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
      "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
      "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
      "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
      "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
      "           9.9955e-01,  3.0000e-03,  1.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "#构造position embedding\n",
    "position_mat=torch.arange(max_position_len).reshape(-1,1)\n",
    "i_mat=torch.pow(10000,torch.arange(0,8,2).reshape(1,-1)/model_dim)\n",
    "pe_embedding_table=torch.zeros(max_position_len,model_dim)\n",
    "pe_embedding_table[:,0::2]=torch.sin(position_mat/i_mat)\n",
    "pe_embedding_table[:,1::2]=torch.cos(position_mat/i_mat)\n",
    "\n",
    "pe_embedding=nn.Embedding(max_position_len,model_dim)\n",
    "pe_embedding.weight=nn.Parameter(pe_embedding_table,requires_grad=False)\n",
    "\n",
    "src_pos=torch.cat([torch.unsqueeze(torch.arange(max(src_len)),0) for _ in src_len]).to(torch.int32)\n",
    "tgt_pos=torch.cat([torch.unsqueeze(torch.arange(max(tgt_len)),0) for _ in tgt_len]).to(torch.int32)\n",
    "\n",
    "src_pe_embedding=pe_embedding(src_pos)\n",
    "tgt_pe_embedding=pe_embedding(tgt_pos)\n",
    "print( src_pe_embedding)\n",
    "print( tgt_pe_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b56b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask形状: torch.Size([2, 5, 5])\n",
      "score形状: torch.Size([2, 5, 5])\n",
      "masked_score: tensor([[[-8.0664e-01,  3.4761e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [ 1.9000e+00,  9.4254e-02, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]],\n",
      "\n",
      "        [[ 1.5015e+00,  7.2953e-01,  8.0450e-01, -1.1050e+00, -1.0000e+09],\n",
      "         [-1.4932e+00, -6.4297e-02,  1.8460e+00, -5.7211e-01, -1.0000e+09],\n",
      "         [-3.0728e-01,  6.9106e-01,  7.9332e-01, -1.2655e+00, -1.0000e+09],\n",
      "         [ 9.9577e-01,  1.0239e+00,  1.3199e+00,  4.8249e-01, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]]])\n"
     ]
    }
   ],
   "source": [
    "valid_encoder_pos = torch.unsqueeze(torch.cat([\n",
    "    torch.unsqueeze(F.pad(torch.ones(L), (0, max_src_seq_len - L)), 0) \n",
    "    for L in src_len\n",
    "]), 2)\n",
    "\n",
    "valid_encoder_pos_matrix = torch.bmm(valid_encoder_pos, valid_encoder_pos.transpose(1, 2))\n",
    "invalid_encoder_pos_matrix = 1 - valid_encoder_pos_matrix\n",
    "mask_encoder_self_attention = invalid_encoder_pos_matrix.to(torch.bool)\n",
    "\n",
    "score = torch.randn(batch_size, max_src_seq_len, max_src_seq_len)\n",
    "\n",
    "masked_score = score.masked_fill(mask_encoder_self_attention, -1e9)\n",
    "prob = F.softmax(masked_score, -1)\n",
    "\n",
    "print(\"mask形状:\", mask_encoder_self_attention.shape)\n",
    "print(\"score形状:\", score.shape)\n",
    "print(\"masked_score:\", masked_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
